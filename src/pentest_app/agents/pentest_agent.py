"""
CrewAI Penetration Testing Agent
===============================

This module implements the main penetration testing agent using CrewAI framework
with Ollama DeepSeek for intelligent reasoning and task orchestration.
"""

import asyncio
import json
from datetime import datetime
from typing import Dict, List, Optional, Any
from dataclasses import dataclass

from crewai import Agent, Task, Crew, Process
from langchain.llms import Ollama
from loguru import logger

from ..modules.recon import ReconModule
from ..modules.vuln_scan import VulnScanModule
from ..modules.exploit import ExploitModule
from ..modules.crack import CrackModule
from ..modules.sniff import SniffModule
from ..utils.opensearch_client import OpenSearchClient, create_pentest_result

@dataclass
class PentestConfig:
    """Configuration for penetration testing workflow."""
    target: str
    run_id: str
    modules_to_run: List[str]
    timeout_per_module: int = 300
    max_concurrent_tasks: int = 2
    ollama_model: str = "deepseek-coder"
    ollama_host: str = "http://localhost:11434"

class PentestAgent:
    """
    Main penetration testing agent that orchestrates various security testing modules
    using CrewAI framework with Ollama DeepSeek for intelligent decision making.
    """
    
    def __init__(self, run_id: str, target: str, opensearch_client: OpenSearchClient):
        """
        Initialize the penetration testing agent.
        
        Args:
            run_id: Unique identifier for this test run
            target: Target URL to test
            opensearch_client: OpenSearch client for logging results
        """
        self.run_id = run_id
        self.target = target
        self.opensearch_client = opensearch_client
        
        # Initialize configuration
        self.config = PentestConfig(
            target=target,
            run_id=run_id,
            modules_to_run=["recon", "vuln_scan", "exploit", "crack", "sniff"]
        )
        
        # Initialize Ollama LLM
        try:
            self.llm = Ollama(
                model=self.config.ollama_model,
                base_url=self.config.ollama_host,
                temperature=0.1  # Low temperature for consistent results
            )
            logger.info(f"Initialized Ollama with model: {self.config.ollama_model}")
        except Exception as e:
            logger.warning(f"Failed to initialize Ollama: {e}. Using fallback reasoning.")
            self.llm = None
        
        # Initialize modules
        self.modules = self._initialize_modules()
        
        # Initialize CrewAI agents
        self.agents = self._create_agents()
        
        # Results storage
        self.results = {
            "run_id": run_id,
            "target": target,
            "start_time": datetime.utcnow().isoformat(),
            "modules": {},
            "summary": {},
            "recommendations": []
        }
    
    def _initialize_modules(self) -> Dict[str, Any]:
        """Initialize all penetration testing modules."""
        return {
            "recon": ReconModule(self.run_id, self.target, self.opensearch_client),
            "vuln_scan": VulnScanModule(self.run_id, self.target, self.opensearch_client),
            "exploit": ExploitModule(self.run_id, self.target, self.opensearch_client),
            "crack": CrackModule(self.run_id, self.target, self.opensearch_client),
            "sniff": SniffModule(self.run_id, self.target, self.opensearch_client)
        }
    
    def _create_agents(self) -> Dict[str, Agent]:
        """Create CrewAI agents for different penetration testing phases."""
        
        # Reconnaissance Agent
        recon_agent = Agent(
            role='Reconnaissance Specialist',
            goal=f'Gather comprehensive information about the target {self.target}',
            backstory="""You are an expert reconnaissance specialist with deep knowledge of 
                        information gathering techniques. You use various tools like Nmap, 
                        DNS enumeration, and OSINT to build a complete picture of the target.""",
            verbose=True,
            allow_delegation=False,
            llm=self.llm
        )
        
        # Vulnerability Scanner Agent
        vuln_agent = Agent(
            role='Vulnerability Assessment Specialist',
            goal=f'Identify security vulnerabilities in {self.target}',
            backstory="""You are a skilled vulnerability assessment expert who uses tools like 
                        Nikto, ZAP, and custom scanners to identify security weaknesses. You 
                        prioritize findings based on severity and exploitability.""",
            verbose=True,
            allow_delegation=False,
            llm=self.llm
        )
        
        # Exploitation Agent
        exploit_agent = Agent(
            role='Penetration Testing Specialist',
            goal=f'Safely test exploitability of vulnerabilities found in {self.target}',
            backstory="""You are an ethical penetration tester who carefully validates 
                        vulnerabilities without causing damage. You use tools like SQLMap, 
                        Metasploit, and custom exploits while maintaining strict ethical boundaries.""",
            verbose=True,
            allow_delegation=False,
            llm=self.llm
        )
        
        # Analysis Agent
        analysis_agent = Agent(
            role='Security Analysis Coordinator',
            goal='Analyze results and provide actionable security recommendations',
            backstory="""You are a senior security analyst who synthesizes findings from 
                        various security tools and provides comprehensive reports with 
                        prioritized recommendations for remediation.""",
            verbose=True,
            allow_delegation=True,
            llm=self.llm
        )
        
        return {
            "recon": recon_agent,
            "vuln_scan": vuln_agent,
            "exploit": exploit_agent,
            "analysis": analysis_agent
        }
    
    def _create_tasks(self, modules_to_run: Optional[List[str]] = None) -> List[Task]:
        """Create CrewAI tasks for the penetration testing workflow."""
        
        if not modules_to_run:
            modules_to_run = self.config.modules_to_run
        
        tasks = []
        
        # Reconnaissance Task
        if "recon" in modules_to_run:
            recon_task = Task(
                description=f"""
                Perform comprehensive reconnaissance on target {self.target}.
                
                Steps:
                1. DNS enumeration and subdomain discovery
                2. Port scanning with Nmap
                3. Service version detection
                4. Operating system fingerprinting
                5. Web technology identification
                
                Provide a detailed report of all discovered assets and services.
                """,
                agent=self.agents["recon"],
                expected_output="Detailed reconnaissance report with discovered services, ports, and technologies"
            )
            tasks.append(recon_task)
        
        # Vulnerability Scanning Task
        if "vuln_scan" in modules_to_run:
            vuln_task = Task(
                description=f"""
                Conduct vulnerability assessment on target {self.target}.
                
                Steps:
                1. Web application vulnerability scanning with Nikto
                2. OWASP ZAP baseline scan
                3. SSL/TLS configuration assessment
                4. Directory and file enumeration
                5. Common vulnerability checks
                
                Prioritize findings by severity and provide exploitation likelihood.
                """,
                agent=self.agents["vuln_scan"],
                expected_output="Vulnerability assessment report with severity ratings and remediation guidance"
            )
            tasks.append(vuln_task)
        
        # Exploitation Task
        if "exploit" in modules_to_run:
            exploit_task = Task(
                description=f"""
                Safely test identified vulnerabilities in {self.target}.
                
                Steps:
                1. SQL injection testing with SQLMap
                2. Authentication bypass attempts
                3. Cross-site scripting (XSS) validation
                4. File upload vulnerability testing
                5. Business logic flaw identification
                
                IMPORTANT: Only perform safe, non-destructive tests. Do not modify data.
                """,
                agent=self.agents["exploit"],
                expected_output="Exploitation test results with proof-of-concept demonstrations"
            )
            tasks.append(exploit_task)
        
        # Analysis and Reporting Task
        analysis_task = Task(
            description=f"""
            Analyze all penetration testing results for {self.target} and create comprehensive report.
            
            Steps:
            1. Consolidate findings from all modules
            2. Assess overall security posture
            3. Prioritize vulnerabilities by risk
            4. Provide specific remediation recommendations
            5. Create executive summary
            
            Generate actionable insights for security improvement.
            """,
            agent=self.agents["analysis"],
            expected_output="Comprehensive security assessment report with prioritized recommendations"
        )
        tasks.append(analysis_task)
        
        return tasks
    
    async def execute_pentest(self, modules_to_run: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        Execute the complete penetration testing workflow.
        
        Args:
            modules_to_run: Specific modules to execute (optional)
            
        Returns:
            Dictionary containing all test results and analysis
        """
        try:
            logger.info(f"Starting penetration test for {self.target} (Run ID: {self.run_id})")
            
            # Log test initiation
            await self.opensearch_client.log_event({
                "run_id": self.run_id,
                "event_type": "pentest_started",
                "target": self.target,
                "modules": modules_to_run or self.config.modules_to_run,
                "timestamp": datetime.utcnow().isoformat()
            })
            
            # Execute individual modules
            if modules_to_run:
                selected_modules = {k: v for k, v in self.modules.items() if k in modules_to_run}
            else:
                selected_modules = self.modules
            
            for module_name, module in selected_modules.items():
                try:
                    logger.info(f"Executing module: {module_name}")
                    
                    # Run module
                    module_results = await module.execute()
                    self.results["modules"][module_name] = module_results
                    
                    # Log module completion
                    await self.opensearch_client.log_event({
                        "run_id": self.run_id,
                        "event_type": "module_completed",
                        "module": module_name,
                        "target": self.target,
                        "findings_count": len(module_results.get("findings", [])),
                        "timestamp": datetime.utcnow().isoformat()
                    })
                    
                except Exception as e:
                    logger.error(f"Module {module_name} failed: {e}")
                    self.results["modules"][module_name] = {
                        "status": "failed",
                        "error": str(e),
                        "timestamp": datetime.utcnow().isoformat()
                    }
            
            # Run CrewAI analysis if LLM is available
            if self.llm:
                try:
                    await self._run_crew_analysis(modules_to_run)
                except Exception as e:
                    logger.error(f"CrewAI analysis failed: {e}")
                    self.results["crew_analysis"] = {"error": str(e)}
            
            # Generate summary
            self._generate_summary()
            
            # Log test completion
            self.results["end_time"] = datetime.utcnow().isoformat()
            self.results["status"] = "completed"
            
            await self.opensearch_client.log_event({
                "run_id": self.run_id,
                "event_type": "pentest_completed",
                "target": self.target,
                "total_findings": self._count_total_findings(),
                "duration": self._calculate_duration(),
                "timestamp": datetime.utcnow().isoformat()
            })
            
            logger.info(f"Penetration test completed for {self.target}")
            return self.results
            
        except Exception as e:
            logger.error(f"Penetration test failed: {e}")
            self.results["status"] = "failed"
            self.results["error"] = str(e)
            self.results["end_time"] = datetime.utcnow().isoformat()
            
            await self.opensearch_client.log_event({
                "run_id": self.run_id,
                "event_type": "pentest_failed",
                "target": self.target,
                "error": str(e),
                "timestamp": datetime.utcnow().isoformat()
            })
            
            return self.results
    
    async def _run_crew_analysis(self, modules_to_run: Optional[List[str]] = None):
        """Run CrewAI crew for intelligent analysis of results."""
        try:
            # Create tasks
            tasks = self._create_tasks(modules_to_run)
            
            # Create crew
            crew = Crew(
                agents=list(self.agents.values()),
                tasks=tasks,
                process=Process.sequential,
                verbose=True
            )
            
            # Execute crew (note: this is typically synchronous in CrewAI)
            crew_result = crew.kickoff()
            
            self.results["crew_analysis"] = {
                "status": "completed",
                "result": str(crew_result),
                "timestamp": datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            logger.error(f"CrewAI execution failed: {e}")
            self.results["crew_analysis"] = {
                "status": "failed",
                "error": str(e),
                "timestamp": datetime.utcnow().isoformat()
            }
    
    def _generate_summary(self):
        """Generate a summary of all penetration testing results."""
        total_findings = self._count_total_findings()
        high_severity = self._count_by_severity("high")
        medium_severity = self._count_by_severity("medium")
        low_severity = self._count_by_severity("low")
        
        self.results["summary"] = {
            "total_findings": total_findings,
            "high_severity": high_severity,
            "medium_severity": medium_severity,
            "low_severity": low_severity,
            "modules_executed": list(self.results["modules"].keys()),
            "successful_modules": [
                name for name, result in self.results["modules"].items() 
                if result.get("status") != "failed"
            ],
            "failed_modules": [
                name for name, result in self.results["modules"].items() 
                if result.get("status") == "failed"
            ]
        }
        
        # Generate basic recommendations
        if high_severity > 0:
            self.results["recommendations"].append(
                "Immediate attention required for high-severity vulnerabilities"
            )
        if medium_severity > 0:
            self.results["recommendations"].append(
                "Address medium-severity vulnerabilities in next maintenance cycle"
            )
        if total_findings == 0:
            self.results["recommendations"].append(
                "No vulnerabilities found, but consider deeper testing"
            )
    
    def _count_total_findings(self) -> int:
        """Count total findings across all modules."""
        total = 0
        for module_result in self.results["modules"].values():
            if isinstance(module_result, dict) and "findings" in module_result:
                total += len(module_result["findings"])
        return total
    
    def _count_by_severity(self, severity: str) -> int:
        """Count findings by severity level."""
        count = 0
        for module_result in self.results["modules"].values():
            if isinstance(module_result, dict) and "findings" in module_result:
                for finding in module_result["findings"]:
                    if finding.get("severity", "").lower() == severity.lower():
                        count += 1
        return count
    
    def _calculate_duration(self) -> str:
        """Calculate test duration."""
        try:
            start = datetime.fromisoformat(self.results["start_time"])
            end = datetime.fromisoformat(self.results["end_time"])
            duration = end - start
            return str(duration)
        except:
            return "unknown"